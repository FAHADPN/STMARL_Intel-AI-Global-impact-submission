{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FAHADPN/STMARL_Intel-AI-Global-impact-submission/blob/main/VhclDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is transfered learned Model for vehicle detection which is based on the VGG16 model architecture\n"
      ],
      "metadata": {
        "id": "yIkbPg_ns7Kd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K9HOqQnewAmI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fXF0A6teWqF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607b05f0-15fc-4075-b5c8-70807dce31eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = torchvision.models.vgg16(pretrained = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8Wm8GpXwYV1L"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UwYu4D2MgXOM"
      },
      "outputs": [],
      "source": [
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "awhAyuSselDY"
      },
      "outputs": [],
      "source": [
        "model2 = copy.deepcopy(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJq2fV1ZgcJw",
        "outputId": "5cd2d4fd-b639-48e5-daf5-227514678887"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model2 = model\n",
        "model2.load_state_dict(copy.deepcopy(model.state_dict()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hafIP71hFOm",
        "outputId": "16d3f586-f444-4171-a977-3b1304a34d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Data import "
      ],
      "metadata": {
        "id": "wWgZYac2yxql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK6emGFqBaly"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('cars.csv')\n",
        "\n",
        "Y = []\n",
        "\n",
        "for i in range(14):\n",
        "  Y.append([df['X'][i],df['Y'][i],df['X'][i+1],df['Y'][i+1]])\n",
        "  #Y.append(df['Y'][i])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERjw318PktF3"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#assert os.environ['COLAB_TPU_ADDR']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2yl8VAwlBSp"
      },
      "outputs": [],
      "source": [
        "#!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtjJJgQNlqt3"
      },
      "outputs": [],
      "source": [
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading vehicle images"
      ],
      "metadata": {
        "id": "12D31aqUy-xy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQSoJmyXNJ7l",
        "outputId": "62026dbb-0657-41c2-f6fe-cc7ba5bb3e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "yay\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
          ]
        }
      ],
      "source": [
        "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "'''\n",
        "frame = [0]*11\n",
        "frame[0] = cv2.imread(\"object_1.jpg\")\n",
        "#frame[1] = cv2.imread(\"object_2.jpg\")\n",
        "#frame[2] = cv2.imread(\"object_3.jpg\")\n",
        "frame[1] = cv2.imread(\"object_4.jpg\")\n",
        "frame[2] = cv2.imread(\"object_5.jpg\")\n",
        "frame[3] = cv2.imread(\"object_6.jpg\")\n",
        "frame[4] = cv2.imread(\"object_7.jpg\")\n",
        "frame[5] = cv2.imread(\"object_8.jpg\")\n",
        "frame[6] = cv2.imread(\"object_9.jpg\")\n",
        "frame[7] = cv2.imread(\"object_10.jpg\")\n",
        "frame[8] = cv2.imread(\"object_11.jpg\")\n",
        "frame[9] = cv2.imread(\"object_12.jpg\")\n",
        "frame[10] = cv2.imread(\"object_13.jpg\")\n",
        "'''\n",
        "frame = []\n",
        "\n",
        "for i in range(1,20):\n",
        "  im = cv2.imread(f'car_img{i}.jpg')\n",
        "  frame.append(im)\n",
        "\n",
        "frame = np.array(frame,dtype = np.float32)\n",
        "X = torch.tensor(frame,dtype=torch.float32,device = dev)\n",
        "X = X.transpose(3,1)\n",
        "X = X.transpose(3,2)\n",
        "\n",
        "mean = torch.mean(X)\n",
        "var = torch.var(X)\n",
        "X_normalized = (X - mean)/torch.sqrt(var)\n",
        "X_normalized.to(dev)\n",
        "Y = torch.tensor(Y,dtype = torch.float32,device = dev)\n",
        "#Y = torch.tensor([[375,307,310,307],[501,318,436,318],[358,321,292,321],[277,164,231,130],[107,182,49,200],[438,248,458,196],[416,230,416,179],[297,287,300,238],[317,261,269,261],[560,249,505,257],[501,257,483,283],[299,182,281,168],[494,244,391,244],[568,379,458,379],[349,260,305,277],[197,295,138,319]],dtype = torch.float32).cuda()\n",
        "\n",
        "print('yay')\n",
        "mean = torch.mean(Y)\n",
        "var = torch.var(Y)\n",
        "Y_normalized = (Y - mean)/torch.sqrt(var)\n",
        "Y_normalized.to(dev)\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(),lr = 0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UBiT8C7FMrzl"
      },
      "outputs": [],
      "source": [
        "model2.classifier.fc = nn.Linear(1000,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRX0j4w-19xN",
        "outputId": "a7f533ad-2d73-4a13-e9ab-c42fa9857333"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "    (fc): Linear(in_features=1000, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model2.requires_grad_(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD6AOwOfIEKj",
        "outputId": "62a69c84-f6fe-4055-d75a-5c2988361944"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "    (fc): Linear(in_features=1000, out_features=8, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.to(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2CFZErl2iuQ",
        "outputId": "bbc124f8-e39d-499c-f2ec-7ed643945019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0/1000 Loss:0.9968787431716919\n",
            "Epoch:50/1000 Loss:0.6020180583000183\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7e67686e56d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch:{epoch}/1000 Loss:{l}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.008\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"At Epoch:{epoch},Loss:{l}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Training:\n",
        "for epoch in range(1000):\n",
        "  out = model2(X_normalized)\n",
        "  l = loss(out,Y_normalized)\n",
        "  if epoch%50 == 0:\n",
        "    print(f\"Epoch:{epoch}/1000 Loss:{l}\")\n",
        "  if l < 0.008:\n",
        "    print(f\"At Epoch:{epoch},Loss:{l}\")\n",
        "    break\n",
        "  optimizer.zero_grad()\n",
        "  l.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "#print(model2(X_normalized))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GLq_VFlBHgVX"
      },
      "outputs": [],
      "source": [
        "print(out.shape)\n",
        "print(Y_normalized.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0UO5FtG62pe6"
      },
      "outputs": [],
      "source": [
        "print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hhfsR_j7Mnl4"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rxRzkd8bJpub"
      },
      "outputs": [],
      "source": [
        "T = model2(X_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KZ_twRWxHnF6"
      },
      "outputs": [],
      "source": [
        "T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AvWM9iTBNSrE"
      },
      "outputs": [],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GcAte_7LIZyA"
      },
      "outputs": [],
      "source": [
        "val = 480*-0.9139\n",
        "print(val)\n",
        "print(val/2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Toc-MNGREFQk"
      },
      "outputs": [],
      "source": [
        "model2 = torch.load('/content/gdrive/My Drive/CarPredictorVGG16based.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f0Cu6wBRFeM-"
      },
      "outputs": [],
      "source": [
        "model2.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nIECah5vFwFh"
      },
      "outputs": [],
      "source": [
        "model2.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rbCvJvofIhgN"
      },
      "outputs": [],
      "source": [
        "Y_predicted = T*torch.sqrt(var) + mean\n",
        "print(Y_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gRouYtBDNw5s"
      },
      "outputs": [],
      "source": [
        "img2 = [0]*3\n",
        "img2[0] = cv2.imread(\"object_13.jpg\")\n",
        "img2[1] = cv2.imread(\"object_12.jpg\")\n",
        "img2[2] = cv2.imread(\"object_1.jpg\")\n",
        "test_data = torch.tensor(img,dtype=torch.float32).cuda()\n",
        "test_data = test_data.transpose(3,1)\n",
        "test_data = test_data.transpose(3,2)\n",
        "mean2 = torch.mean(test_data)\n",
        "var2 = torch.var(test_data)\n",
        "test_data_normalized = (test_data - mean2)/torch.sqrt(var2)\n",
        "\n",
        "T2 = model2(test_data_normalized)\n",
        "print(T2)\n",
        "T2_denormalized = T2*torch.sqrt(var) + mean\n",
        "print(T2_denormalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WTkLjXL-JUWu"
      },
      "outputs": [],
      "source": [
        "cv2.circle(img2[2],(529,160),5,(255,0,0),5)\n",
        "cv2_imshow(img2[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YYYsWI6dG-0K"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#cv2.circle(img[2],(525,162),5,(0,255,0),3)\n",
        "#but the model has to be trained for couple more epochs to get good at this\n",
        "#and also I have to make the data have enough training samples for both kind of objects to generalize on the data\n",
        "#and also make a nice and clear data with rotations in them\n",
        "cv2_imshow(img[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lUV2hc2tZVu4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Yq3fP39OXeMM"
      },
      "outputs": [],
      "source": [
        "model_name = 'CarPredictorVGG16based.pt'\n",
        "path = f\"/content/gdrive/My Drive/{model_name}\"\n",
        "torch.save(model2,path)\n",
        "print(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I have to use the outputs of these detector to predict the bounding boxes of the vehicles in the frames and then use the bbox labeled images as the input for the DeepReinforcement Learning Agent for Training Him to be like an Intelligent Traffic Police"
      ],
      "metadata": {
        "id": "t6TRkjjyz0xZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the DQN for training the Agent\n",
        "Gotta use this"
      ],
      "metadata": {
        "id": "Gg66m9e83SfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self,input_size,output_size,hidden_size):\n",
        "        super(DQN,self).__init__()\n",
        "\n",
        "       self.attention = Multi_Headed_Attention(hidden_size,hidden_size,out_size)\n",
        "        self.conv1 = nn.Conv2d(in_channels,in_channels,2)\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(out_channels,out_channels,2)\n",
        "\n",
        "        self.fc1 = nn.Linear(10*79*59,hidden_size)\n",
        "        self.relu = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(800,100,bias = True)\n",
        "        self.out = nn.Linear(300,out_size)\n",
        "        self.dropout = nn.Dropout(p = 0.5)\n",
        "    def forward(self,X):\n",
        "\n",
        "        \n",
        "        out = self.relu(self.conv1(X))\n",
        "        out = self.maxpool(out)\n",
        "        out = self.relu(self.conv2(out))\n",
        "        out = self.maxpool(out)\n",
        "        out = self.relu(self.fc1(out.reshape(-1,10*79*59)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.MultiheadedAttention(out)\n",
        "        out = self.relu(self.fc2(out))\n",
        "        \n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Multi_headed_attention(nn.Module):\n",
        "\n",
        "    def __init__(self,embeddings,head_dim,num_heads = 2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.head_dim = head_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.queries = nn.Linear(embeddings,num_heads*head_dim)\n",
        "        self.keys = nn.Linear(embeddings,num_heads*head_dim)\n",
        "        self.values = nn.Linear(embeddings,num_heads*head_dim)\n",
        "        self.softmax = nn.Softmax(dim = -1)\n",
        "        self.unify = nn.Linear(num_heads*head_dim,head_dim)\n",
        "\n",
        "    def forward(self,X):\n",
        "        bs,seq,embed_dim = X.shape\n",
        "        Q = self.queries(X).view(bs,seq,self.num_heads,self.head_dim).transpose(1,2)\n",
        "        K = self.keys(X).view(bs,seq,self.num_heads,self.head_dim).transpose(1,2)\n",
        "        V = self.values(X).view(bs,seq,self.num_heads,self.head_dim).transpose(1,2)\n",
        "        K = K.transpose(-1,-2)\n",
        "        attn_scores = torch.matmul(Q,K)/(self.head_dim**(1/float(2)))\n",
        "        softmaxed_attn_scores = self.softmax(attn_scores)\n",
        "        out = torch.matmul(softmaxed_attn_scores,V)\n",
        "        out = out.transpose(1,2).contiguous().view(bs,seq,self.num_heads*self.head_dim)\n",
        "        out = self.unify(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class replay_memory():\n",
        "\n",
        "    def __init__(self,capacity):\n",
        "\n",
        "        self.experience = namedtuple('memory',('action','state','next_state','reward'))\n",
        "        self.replay_memory = []\n",
        "        self.capacity = capacity\n",
        "        train_data = []\n",
        "\n",
        "    def get_memory(self,state,action,next_state,reward):\n",
        "        for i in range(len(states)):\n",
        "            e = self.experience(action[i],state[i],next_state[i],reward[i])\n",
        "            if len(self.replay_memory) < self.capacity:\n",
        "                self.replay_memory.append(e)\n",
        "\n",
        "            else:\n",
        "                self.replay_memory.pop(-1)\n",
        "                self.replay_memory.insert(0,e)\n",
        "\n",
        "    def sample_memory(self,batch_size):\n",
        "        return random.sample(self.replay_memory,batch_size)\n",
        "    def memory_length(self):\n",
        "        return len(self.replay_memory)\n",
        "    def print_memory(self):\n",
        "        return self.replay_memory\n"
      ],
      "metadata": {
        "id": "zGowDgim090W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "VhclDetector.ipynb",
      "provenance": [],
      "mount_file_id": "1o6h54Qgda50an7mxla2_p6cwDE-COk5S",
      "authorship_tag": "ABX9TyOtppeK5XzaPnW1As7eGpIP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}